\appendix

\section{More details on the reasoning strategy}
\label{sec:append}

\captionsetup[subfigure]{labelformat=empty}
\begin{figure}[htbp]
	\begin{center}
		Question: \textbf{Does color of u now equal the color of the latest circle?}
	\end{center}
	\vskip -0.4cm
	\null\hfill
	\begin{subfigure}{0.25\textwidth}
		\includegraphics[width=0.9\linewidth]{"../img/visualization/experiment_run_20190917_022319/Frame 1"}
		\caption{Frame: \textbf{1}\newline Ground Truth: \textbf{false}}
		\label{fig:frame-1}
	\end{subfigure}%
	\hfill
	\begin{subfigure}{0.25\textwidth}
		\centering
		\includegraphics[width=0.9\linewidth]{"../img/visualization/experiment_run_20190917_022319/Frame 2"}
		\caption{Frame: \textbf{2}\newline Ground Truth: \textbf{false}}
		\label{fig:frame-2}
	\end{subfigure}%
	\hfill
	\begin{subfigure}{0.25\textwidth}
		\centering
		\includegraphics[width=0.9\linewidth]{"../img/visualization/experiment_run_20190917_022319/Frame 3"}
		\caption{Frame: \textbf{3}\newline Ground Truth: \textbf{true}}
		\label{fig:frame-3}
	\end{subfigure}%
	\hfill
	\begin{subfigure}{0.25\textwidth}
		\centering
		\includegraphics[width=0.9\linewidth]{"../img/visualization/experiment_run_20190917_022319/Frame 4"}
		\caption{Frame: \textbf{4}\newline Ground Truth: \textbf{true}}
		\label{fig:frame-4}
	\end{subfigure}%
	\hfill\null
	\newline
	\centering
	\caption{A sample from the COG dataset selected for the following analysis.} 
	\label{fig:example-app}  
\end{figure}


As a result of training the SAMNet developed a quite complex reasoning strategy.
We will illustrate the key reasoning steps taken by the model on the example presented in \cref{fig:example-app}.
We have decided to pick the sample from the \textbf{CompareColor} task.	

First, let us analyze, independently of SAMNet, what are the key operations that one would need to perform in order to provide the correct answers. 
As the question concerns both the \textbf{now} and \textbf{latest} temporal contexts, in the Frame \textbf{1} one should look for both \textbf{u} and \textbf{circle} objects, look at their colors (different), and provide the answer \textbf{false}.
Next, one should also memorize the \textbf{pink circle} and move to next Frame.
Analogically, in Frame \textbf{2} there are both objects present, both with different colors, so the answer is once again \textbf{false}.
However, from that point we do not care anymore about the \textbf{pink circle} and should remember the \textbf{yellow circle} instead.
This is of utmost importance for the following two frames, as there are no circles present there.
So when analyzing Frames \textbf{3} and \textbf{4} one need to recall the \textbf{yellow circle} from the memory and compare its color with the color of \textbf{u}'s -- as in both cases they are yellow, thus  both answers should be \textbf{true}.

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.95\textwidth]{"../img/visualization/experiment_run_20190917_022319/Frame 2 Step 1"}
	\caption{State of the SAM Cell after 1-st step of reasoning on Frame 2.} 
	\label{fig:frame-2-step-1-app}
\end{figure}

As full step-by-step analysis (8 reasoning steps for each of 4 frames) would significantly exceed the page limits, we have cherry picked four steps of reasoning performed by our SAMNet model.
Let us start from \textbf{1}-st reasoning step on Frame \textbf{2}, as visualized in \cref{fig:frame-2-step-1-app} and focus on different aspects of the model.
First, the attention over both the question and image is clearly focusing over the \textbf{u} -- despite we have never trained the system with "word \textbf{u}"-"visual object \textbf{u}" pairs, the SAM Network managed to develop visual grounding on its own.
Second, the time context is clearly focused on \text{Now} -- once again, during the training we have never instructed that the system should pay attention to this (or any other) particular word and the system learned to catch the temporal context on its own (i.e. learned to use the provided mechanisms in the correct way).
Third, as write head is always pointing at "free memory slot", we can notice that there is an object already stored in memory under address 1.
This is the \textbf{pink circle} object memorized during the analysis of the Frame \textbf{1}.
However, we can also notice that the 2nd slot seems to be partially "polluted" by the object from slot 1, which indicates that the write head was not perfectly focused on a single memory address (similarly to the current state).


\begin{figure}[!h]
\centering
  \includegraphics[width=0.95\textwidth]{"../img/visualization/experiment_run_20190917_022319/Frame 2 Step 6"}
\caption{State of the SAM Cell after 6-th step of reasoning on Frame 2.} 
\label{fig:frame-2-step-6-app}
\end{figure}

Next, let us analyze the \textbf{6}-th reasoning step presented~\cref{fig:frame-2-step-6-app}.
Here the system clearly focuses its attention on the second object important from the point of view of the question: the \textbf{yellow circle}.
Analogically, the question and visual attention are almost perfectly aligned with the word and object, and, besides, the system  properly caught the time context of the object: \textbf{Latest}.
Additionally, the "Add New" gate is on, the memory address 2 has a different content and write head moved to the next address.
Those are clear indicators that the system has stored the \textbf{yellow circle} in the external memory.
Sadly, also  in here we observe the "pollution" of addresses 3 and 4.

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.95\textwidth]{"../img/visualization/experiment_run_20190917_022319/Frame 4 Step 1"}
	\caption{State of the SAM Cell after 1-st step of reasoning on Frame 4.} 
	\label{fig:frame-4-step-1-app}
\end{figure}

Let us now fast-forward to analogical reasoning steps in Frame \textbf{6}.
In the \textbf{1}-st reasoning step (\cref{fig:frame-4-step-1-app}) we can once again observe that  system correctly grounded the visual object \textbf{u} and detected the correct temporal context \textbf{Now}.
Besides that, we can notice that memory content remained more or less unchanged, despite the fact that write head shifted to the next memory address (it also became more soft, pointing at addresses 4 and 5).

\begin{figure}[!h]
	\centering
	\includegraphics[width=0.95\textwidth]{"../img/visualization/experiment_run_20190917_022319/Frame 4 Step 6"}
	\caption{State of the SAM Cell after 6-th step of reasoning on Frame 4.} 
	\label{fig:frame-4-step-6-app}
\end{figure}

In \textbf{6}-th reasoning step (\cref{fig:frame-4-step-6-app}) there are several things worth discussing.
First, question attention is pointing at the word \textbf{circle}, but the visual attention is clearly avoiding all the objects. 
This is because there is no circle.
However, as the system properly identified the temporal context as \textbf{Latest}, instead of using the visual object, it uses the object retrieved from the memory -- please notice that the read head, despite not being perfectly crisp, is pointing at addresses 3-5, where it previously stored the \textbf{yellow circle} during the analysis of Frame \textbf{2}.
Moreover, the ``Add New`` gate value is high enough so it once again updates the memory, with void object. 
But please notice that the content of those memory addresses is negligible, and at the end the SAMNet model is still able return the correct prediction.

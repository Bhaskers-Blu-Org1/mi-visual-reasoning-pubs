\section{Experiments}

We analyze MAC's generalization and transfer learning abilities by testing it on the CLEVR-CoGenT dataset. It is synthesized in the same way as CLEVR, but contains two conditions: in Condition A, all cubes are gray, blue, brown, or yellow and all cylinders are red, green, purple, or cyan; in Condition B, cubes and cylinders swap color palettes. Both conditions contain spheres of all colors. We also evaluate the simplified model on this dataset for comparison.

The training procedure is layed out as follows: we train the MAC model (and simplified MAC) for 20 epochs on 90\% of the training sets of CLEVR \& CoGenT separately. We keep the remaining 10\% for validating the model at every epoch, and use the original validation sets as test sets.
%given that the ground truth labels for the true test sets are not available.

We implemented both versions of the MAC model using PyTorch v0.4.0~\cite{paszke2017automatic}. We relied on the MI-Prometheus~\cite{kornuta2018accelerating} framework for training and testing both variants\footnote{The code \& the training settings are available at \url{https://github.com/IBM/mi-prometheus/}}. For training, we used NVIDIA's GeForce GTX TITAN X. We followed the implementation details indicated in the  supplemental material (Sec. A) of the original paper~\cite{hudson2018compositional}, to ensure a faithful comparison.

\begin{table}[]
	\caption{CLEVR \& CoGenT accuracies for the MAC \& S-MAC models}
	\centering
	\begin{tabular}{ccccCcCc}
		\toprule
		\multirow{2}{*}{Model} & \multicolumn{3}{c}{Training} &  \multicolumn{2}{c}{Fine-tuning} &  \multicolumn{2}{c}{Test} \\
		\cmidrule{2-4} \cmidrule{5-6} \cmidrule{7-8} 
		& Dataset                & Time [h:m] & Acc [\%]          & Dataset & Acc [\%]  & Dataset & Acc [\%] \\
		\midrule
		\multirow{15}{*}{MAC} & \multirow{10}{*}{CLEVR}  & \multirow{10}{*}{30:52}  & \multirow{10}{*}{96.70} & \multirow{4}{*}{--}   & \multirow{4}{*}{--}  & CLEVR    & 96.17          \\
		\cmidrule{7-8} 
		 &                        &  &               &     &                                & CoGenT-A    &  96.22   \\
		\cmidrule{7-8} 
		  &                        &   &              &     &                               & CoGenT-B   & 96.27  \\

		\cmidrule{5-6} \cmidrule{7-8} 
		&                             &                                         &    &   \multirow{2}{*}{CoGenT-A}         &       \multirow{2}{*}{x}          & CoGenT-A &  x         \\
		\cmidrule{7-8} 
		&                             &                                         &       &         &                & CoGenT-B &    x       \\
		\cmidrule{5-6} \cmidrule{7-8} 
		&                             &                                         &    &   \multirow{2}{*}{CoGenT-B}         &       \multirow{2}{*}{x}          & CoGenT-A &  x         \\
		\cmidrule{7-8} 
		&                             &                                         &       &         &                & CoGenT-B &    x       \\  
		  
		\cmidrule{2-4} \cmidrule{5-6} \cmidrule{7-8} 
		& \multirow{5}{*}{CoGenT-A} & \multirow{5}{*}{30:52}     & \multirow{5}{*}{97.02}   &  \multirow{2}{*}{--}  &  \multirow{2}{*}{--}    & CoGenT-A & 96.88         \\
		\cmidrule{7-8} 
		&                             &                                         &       &         &                & CoGenT-B & 79.54          \\
		\cmidrule{5-6} \cmidrule{7-8} 
		&                             &                                         &    &   \multirow{2}{*}{CoGenT-B}         &       \multirow{2}{*}{97.91}          & CoGenT-A &  92.06         \\
		\cmidrule{7-8} 
		&                             &                                         &       &         &                & CoGenT-B &    95.62       \\
		\midrule
		\multirow{15}{*}{S-MAC} & \multirow{10}{*}{CLEVR}  & \multirow{10}{*}{28:30}  & \multirow{10}{*}{95.82} & \multirow{3}{*}{--}   & \multirow{3}{*}{--}  & CLEVR    & 95.29           \\
		\cmidrule{7-8} 
		&                        &  &               &     &                                & CoGenT-A    &  95.47   \\
		\cmidrule{7-8} 
		&                        &   &              &     &                               & CoGenT-B   &  95.58  \\		
		
		\cmidrule{5-6} \cmidrule{7-8} 
		&                             &                                         &    &   \multirow{2}{*}{CoGenT-A}         &       \multirow{2}{*}{x}          & CoGenT-A &  x         \\
		\cmidrule{7-8} 
		&                             &                                         &       &         &                & CoGenT-B &    x       \\
		\cmidrule{5-6} \cmidrule{7-8} 
		&                             &                                         &    &   \multirow{2}{*}{CoGenT-B}         &       \multirow{2}{*}{x}          & CoGenT-A &  x         \\
		\cmidrule{7-8} 
		&                             &                                         &       &         &                & CoGenT-B &    x       \\  		
		
		\cmidrule{2-4} \cmidrule{5-6} \cmidrule{7-8} 
		& \multirow{5}{*}{CoGenT-A}   & \multirow{5}{*}{28:33}   & \multirow{5}{*}{96.09}  &  \multirow{2}{*}{--}  &  \multirow{2}{*}{--}   & CoGenT-A & 95.91          \\
		\cmidrule{7-8} 
		&                             &                                         &     &          &                & CogenT-B & 78.71          \\
		\cmidrule{5-6} \cmidrule{7-8} 
		&                             &                                         &    &   \multirow{2}{*}{CoGenT-B}         &       \multirow{2}{*}{96.85}          & CoGenT-A &  x         \\
		\cmidrule{7-8} 
		&                             &                                         &       &         &                & CoGenT-B &    x       \\
		\bottomrule
	\end{tabular}
	\label{results}
\end{table}

We report the obtained scores in \tableref{results}. Taking the evaluation of MAC on CLEVR as a reference experiment, it yields an accuracy of 96.2\%, obtained after 31.9h of training. The training wall time is coherent with what is reported in the original paper (roughly 30h of training for 20 epochs)\vmf{Not sure if we should explain in more details why there's a 3\% gap..}
Evaluating MAC on CoGenT shows that, like previous work (\cite{johnson2017inferring}, \cite{mascharka2018transparency})], the performance is worse on Condition B than Condition A after training only using Condition A data. As \tableref{results} shows, the MAC model achieves 79.5\% accuracy on Condition B, and 96.9\% on Condition A.
The simplified MAC reaches an accuracy of 95.3\% on CLEVR, which is close to the reference score. Moreover, it presents the advantage to train faster, showing a decrease of 10.5\% in wall time. This point also holds true when training on CoGenT: not only does the simplified model trains faster, it also presents comparable performance when evaluated on both conditions. The scores obtained on both conditions are coherent with the ones of MAC, indicating that the simplifications did not hinder its generalization capability.

Following (\cite{johnson2017inferring}, \cite{perez2017film}), we then fine-tune both models using 3k images and 30k questions from the Condition B data, and re-evaluate them on both conditions.

\section{Introduction}
Reasoning over visual inputs is a fundamental characteristic of human intelligence.
Reproducing this ability with artificial systems is a challenge that requires learning relations and compositionality~\cite{hu2017learning, johnson2017inferring}. The Visual Question Answering (VQA)~\cite{antol2015vqa,malinowski2014towards,wu2017visual} task has been tailored to benchmark this type of reasoning, combining natural language processing and visual recognition.

Many approaches have been explored, such as modular networks, that combine modules coming from a predefined collection \cite{andreas2016learning,johnson2017inferring, mascharka2018transparency}. Attention mechanisms (\cite{bahdanau2014neural}, \cite{xu2015show}) are also used to guide the focus of the system over the image and the question words.

Several VQA datasets have been proposed (e.g. DAQUAR~\cite{malinowski2014multi}, VQA~\cite{antol2015vqa}); nonetheless, these datasets contain several biases (e.g. unbalanced questions or answers) that are often exploited by systems during learning~\cite{goyal2017making}.
The CLEVR dataset~\cite{johnson2017clevr} was designed to address these issues. The synthetic nature of its images \& questions enables detailed analysis of visual reasoning, and allows for variations, to test a particular ability such as generalization or transfer learning. One variation of CLEVR, called CoGenT (Compositional Generalization Test), measures whether models learn separate representations for color and shape instead of memorizing all possible combinations. 
For details, see Appendix~A (all appendices are in the supplementary material).


One of the most recent exciting models aiming at solving VQA is called Memory, Attention, and Composition (MAC)~\cite{hudson2018compositional}, which performs a sequence of attention-based reasoning operations. 
Although the performance of MAC has been proven, several questions arise:
Does the model really learn relations between objects? 
How does the model represent these relations in its reasoning steps? 
Is the model representing concepts like objects attributes (shape, color, size)?

In this work, we further investigate the interpretability and generalization capabilities of the MAC model.
We propose a new set of equations that simplifies the core of the model (S-MAC). It trains faster and achieves comparable accuracy on CLEVR. 
Second, we show that both models achieve comparable performance with zero-shot learning, when trained on CoGenT-A and tested on CoGenT-B. With fine-tuning however, we obtained a significant 15 points increase in the accuracy, matching state-of-the-art results~\cite{perez2017film, mascharka2018transparency}.
Last, we illustrate using CoGenT-B that, without adequate care, fine-tuning can actually reduce a model's accuracy.
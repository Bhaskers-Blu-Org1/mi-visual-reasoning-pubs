\section{Introduction}
Reasoning over visual inputs is a fundamental characteristic of human intelligence.
Reproducing this ability with artificial systems is a challenge that requires learning relations and compositionality~\cite{hu2017learning, johnson2017inferring}. The Visual Question Answering (VQA)~\cite{antol2015vqa,malinowski2014towards,wu2017visual} task has been tailored to benchmark this type of reasoning, combining natural language processing and visual recognition.

Many approaches have been explored, such as modular networks, that combine modules coming from a predefined collection \cite{andreas2016learning,johnson2017inferring, mascharka2018transparency}. Attention mechanisms (\cite{bahdanau2014neural}, \cite{xu2015show}) are also used to guide the focus of the system over the image and the question words.

Several VQA datasets have been proposed (e.g. DAQUAR~\cite{malinowski2014multi}, VQA~\cite{antol2015vqa}); nonetheless, these datasets contain several biases (e.g. unbalanced questions or answers) that are often exploited by systems during learning~\cite{goyal2017making}.
The CLEVR dataset~\cite{johnson2017clevr} was designed to address these issues. The synthetic nature of its images \& questions enables detailed analysis of visual reasoning, and allows for variations, to test a particular ability such as generalization or transfer learning. One variation of CLEVR, called CoGenT (Compositional Generalization Test), measures whether models learn separate representations for color and shape instead of memorizing all possible combinations. 


One of the most recent exciting models aiming at solving VQA is called Memory, Attention, and Composition (MAC)~\cite{hudson2018compositional}, which performs a sequence of attention-based reasoning operations. 
though the performance of MAC has been proven, several questions arise:
Does the model really learn relations between objects? 
How does the model represent these relations in its reasoning steps? 
Is the model representing concepts like objects attributes (shape, color, size)?

In this work, we further investigate the interpretability and generalization capabilities of the MAC model.
We propose a new set of equations that simplifies the core of the model (S-MAC). It trains faster and achieves comparable accuracy on CLEVR. 
Second, we show that both models achieve comparable performance with zero-shot learning, when trained on CoGenT-A and tested on CoGenT-B. With fine-tuning however, we obtained a significant 15 points increase in the accuracy, matching state-of-the-art results~\cite{perez2017film, mascharka2018transparency}.
Last, we illustrate using CoGenT-B that, without adequate care, fine-tuning can actually reduce a model's accuracy.

The paper is organized as follows.
In \sec{datasets} we digest into details of both CLEVR and CoGenT datasets, emphasizing their differences.
Next, in \sec{models}) we present both MAC and S-MAC models and explain what motivated the formulation of equations for the latter.
\sec{experiments} discusses the most important findings when using transfer learning on CLEVR and both versions of CoGenT.
In order to facilitate the lecture in \sec{transfer_learning} we cherry-picked a subset of experiments -- the whole table with comparison of both MAC and S-MAC models when training/fine-tuning/testing can be found in Appendix~\ref{sec:full_comparison}.
In \sec{failures} we present examples that support hypothesis on the lack of disentanglement of concepts in both models.
\sec{comparison} presents results obtained by other state-of-the-art models, and additionally indicates a problem with their reproducibility. 
We conclude the paper in \sec{conclusion}.

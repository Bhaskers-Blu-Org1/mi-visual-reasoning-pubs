\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
%\usepackage{epsfig}
\usepackage{graphicx}
\usepackage[font=small]{subcaption}
\captionsetup[figure]{skip=5pt}
\captionsetup[table]{skip=5pt}
%\setlength{\belowcaptionskip}{-15pt}  % reduce padding below figure
\usepackage{amsmath, amssymb, amsfonts,bm}
\usepackage{amsthm}

% Include other packages here, before hyperref.
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{adjustbox}
\usepackage{tabularx}
\usepackage{xcolor}

\usepackage{hyperref}
\hypersetup{
	pagebackref,
	colorlinks,
	breaklinks,
	bookmarks=false,
	linkcolor={red!50!black},
	citecolor={blue!50!black},
	urlcolor={blue!80!black},
	%linkcolor=OliveGreen,
	%citecolor=Blue,
}
%\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{7813} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\ifcvprfinal\pagestyle{empty}\fi

\usepackage{cleveref}
\crefname{section}{Section}{Sections}
\crefname{figure}{Figure}{Figures}
\crefname{table}{Table}{Tables}
\crefname{appendix}{Appendix}{Appendices}
\crefname{definition}{Definition}{Definitions}

\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{definition}[theorem]{Definition}

\theoremstyle{remark}
\newtheorem*{notation}{Notation}
%\newtheorem*{remark}{Remark}
\newtheorem*{note}{Note}

\newtheorem{fact}{Fact}
\newtheorem*{observation}{Observation}
\newtheorem*{condition}{Condition}
\newtheorem*{claim}{Claim}
\newtheorem*{example}{Example}
\newtheorem*{question}{Question}

\usepackage{enumitem}
\setlist{leftmargin=*}

%% User's macros %%
\newcommand{\Reals}{\mathbb{R}}
\newcommand{\cD}{\mathcal{D}}
\newcommand{\cT}{\mathcal{T}}
\newcommand{\cX}{\mathcal{X}}
\newcommand{\cY}{\mathcal{Y}}
\newcommand{\cQ}{\mathcal{Q}}
\newcommand{\cV}{\mathcal{V}}
\newcommand{\cF}{\mathcal{F}}

\renewcommand{\vec}[1]{\mathbf{#1}}
\newcommand{\vc}{\vec{c}}
\newcommand{\vso}{\vec{so}}
\newcommand{\vone}{\vec{1}}
\newcommand{\proj}{\mathrm{proj}}
\newcommand{\vx}{\vec{x}}
\newcommand{\vy}{\vec{y}}

\newcommand{\imatch}{g^{\mathrm{v}}}
\newcommand{\mmatch}{g^{\mathrm{m}}}

\newcommand{\doadd}{h^{\mathrm{a}}}
\newcommand{\doreplace}{h^{\mathrm{r}}}

\newcommand{\tlast}{\tau^{\mathrm{last}}}
\newcommand{\tlatest}{\tau^{\mathrm{latest}}}
\newcommand{\tnow}{\tau^{\mathrm{now}}}
\newcommand{\tnone}{\tau^{\mathrm{none}}}

\newcommand{\rhead}{\vec{rh}}
\newcommand{\whead}{\vec{wh}}

\newcommand{\uX}{\underline{X}}


\newcommand{\tk}[1]{\textcolor{red}{TK: #1}}
\newcommand{\ao}[1]{\textcolor{green}{AO: #1}}
\newcommand{\tsj}[1]{\textcolor{magenta}{TSJ: #1}}
\newcommand{\vm}[1]{\textcolor{blue}{VM: #1}}

\newcommand{\compresslist}{ % Define a command to reduce spacing within itemize/enumerate environments, this is used right after \begin{itemize} or \begin{enumerate}
\setlength{\itemsep}{1pt}
\setlength{\parskip}{0pt}
\setlength{\parsep}{0pt}}



%%%%%%%%%%%%%%%

\begin{document}

%%%%%%%%% TITLE
\title{Transfer Learning in Visual and Relational Reasoning}

\author{%
	T.S. Jayram\thanks{IBM Research AI.} \and
	Vincent Marois\footnotemark[2] \and
	Tomasz Kornuta\thanks{Nvidia Research.} \and
	Vincent Albouy\thanks{} \and
	Emre Sevgen\thanks{Citrine Informatics.}  \and
	Ahmet Ozcan\footnotemark[2]
}
%
%\author{T.S. Jayram \and  Vincent Marois \and Vincent Albouy \and Tomasz Kornuta  \and Emre Sevgen \and Ahmet Ozcan\\
%IBM Research AI\\
%Almaden Research Center, San Jose, CA 95120, USA\\
%Thomas J. Watson Research Center, Yorktown Heights, NY 10598, USA\\
%{\tt\small {jayram,  asozcan}@us.ibm.com}
%{\tt\small {tkornuta, sesevgen}@gmail.com}
%{\tt\small vincent.marois@ibm.com}
%}

\maketitle

%%%%%%%%% ABSTRACT
\begin{abstract}
Transfer learning has become the de facto standard in computer vision and natural language processing, especially where labeled data is scarce. Accuracy can be significantly improved by using pre-trained models and subsequent fine-tuning. In visual reasoning tasks, such as image question answering, transfer learning is more complex. In addition to transferring the capability to recognize visual features, we also expect to transfer the systemâ€™s ability to reason. Moreover, for video data, temporal reasoning adds another dimension. In this work, we formalize these unique aspects of transfer learning and propose a theoretical framework for visual reasoning, exemplified by the well-established CLEVR and COG datasets. Furthermore, we introduce a new, end-to-end differentiable recurrent model (SAMNet), which shows state-of-the-art accuracy and better performance in transfer learning on both datasets. The improved performance of SAMNet stems from its capability to decouple the abstract multi-step reasoning from the length of the sequence and its selective attention enabling to store only the question-relevant objects in the external memory.
\end{abstract}

%%%%%%%%% BODY TEXT
\input{introduction}

\input{related_work}

\input{samnet}

\input{transfer_learning}

\input{experiments}

\input{summary}

\clearpage
{\small
\bibliographystyle{ieee_fullname}
\bibliography{../bibliography}
}

%\clearpage
%\input{appendix}

\end{document}

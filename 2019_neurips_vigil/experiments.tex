\section{Experiments}


Our experiments were intended to study SAMNet's performances as well as generalization abilities in different settings. For this purpose, we use two different versions of the COG dataset, an easy one (canonical) and a hard version to explore a wide range of difficulties. The following parameters control the difficulty level: the number of frames in the input sequence, the maximum memory duration (how far is the last object to be remembered), and the number of distractors. These parameters are detailed in Table 1 for each setting. The table also shows the size of the training/validation/test split used for our experiments. The COG dataset is composed of 44 tasks that have equal number of samples.
We chose to focus our effort only on the the 22 classification tasks.
We compare our model to the original COG model  ~\cite{yang2018dataset} using their implementation (https://github.com/google/cog) and scores given by the authors. We also use the exact same training parameters detailed in the original paper.

On the other side we trained SAMNet using IBM's Mi-Prometheus~\cite{kornuta2018accelerating}, a framework for research based on Pytorch. We trained all our models using NVIDIAâ€™s GeForce GTX TITAN X GPUs. We trained  SAMNet using 8 reasoning steps SAMCells and a hidden state size of 128. The external memory has 128-bit slots. We trained our model until convergence but we also have set a training time limit of 80 hours.



\begin{table}[!t]
	\centering
	\caption{COG Dataset parameters for the canonical setting and the hard setting  }
	\resizebox{\textwidth}{!}{
	

	\begin{tabular}{ccccccc}
		\toprule
		
		Dataset    &  	number of frames  &  	maximum memory duration & number of distractors & size of training set & size of validation/test set    \\ 
          \midrule
		
		 Canonical setting & 4 & 3 & 1 & 10000320 & 500016 &   \\
		 \midrule
		 
		 Hard  setting & 8 & 7& 10 & 10000320 & 500016  \\
		 \bottomrule
	
	\end{tabular}
}

	
	\label{tab:parameters}
\end{table}



\subsection{Training and testing Methodology}

First we evaluate SAMNet's performance on the canonical setting and compare it with the COG Model. As shown in Table 2 we could achieve a small improvement in accuracy, from 97.6\% for the COG model to 98\% for SAMNet.

Our second goal is to improve the accuracy on the hard dataset. In order to do this, we have tried three different approaches.

The first approach is to train a model on the hard training set only and test it on the hard test set. It is the same approach used by the original COG paper ~\cite{yang2018dataset} to evaluate performance on the hard dataset. We achieve a test accuracy of 91.9 \% which represents a 12\% improvement from the COG model score (see Table 2).
It shows that SAMNet's design choices make a difference when it come to harder tasks with longer sequences and more distractors objects.

The second approach is to see if we can generalize from the easy to the hard setting. We train a model on the canonical dataset and test it on the hard dataset. Doing so we can achieve comparable results than the first approach. It shows that SAMNet has good generalizations abilities. It can adapt well to different sequence lengths and number of distractors.

Finally we train a model on the canonical data set, fine-tune it on the hard data set during only 25k iterations and test it on the hard dataset. Thanks to fine-tuning, we can observe a significant improvement from 91.6\%  to 96.5\% test accuracy which represents the state of the art accuracy for the hard setting (classification tasks).
After a short fine-tuning process, the model can generalize well to harder tasks and even surpass the accuracy obtained in the first approach. We note that the third approach is two time faster than the first one and more effective.


We can also notice a major improvement for the two hardest tasks, AndCompareShape and AndCompareColor. Those two tasks represent a higher level of difficulty due to the number of objects to be remembered in order to answer the question correctly.
As we can see in Table 2 we could achieve a 12\% improvement for the canonical data set and almost a 40\% improvement for the hard dataset.
We see that the SAMNet's external memory plays an important role in remembering objects from the past and this affects the test scores significantly. 






\begin{table}[t]
	
	\caption{COG test set accuracies for  SAMNet \& COG models. For the COG section, the results marked as 'paper' comes from the original COG paper ~\cite{yang2018dataset}, whereas the results marked as 'ours' come from our own experiments using the following implementation: https://github.com/google/cog }
	
	\centering
	\resizebox{\textwidth}{!}{
	\begin{tabular}{ccccccccccc}
		\toprule
		Model & & SAMNet & && && COG&& \\
		\cmidrule{2-5} \cmidrule{7-11} 
		&&&&& & paper & ours & ours & paper&\\
		\cmidrule{7-9} \cmidrule{10-11}
		Trained on       & canonical & canonical & canonical & hard &           &  canonical  & canonical  & canonical & hard \\ 
		Fine tuned on  & - & - & hard  & - &           & -   & - & hard & - \\ 
		Tested on        & canonical & hard & hard & hard &            &canonical  & hard & hard & hard  \\ 
		\midrule
		
		Overall accuracy & 98.0 & 91.6 & 96.5  &  &           & 97.6  & 65.9 & & 80.1 \\ 
		
		\midrule 
		
		
		AndCompareColor	&	93.5		&	82.7	&	89.2	&&		&81.9	&57.1&  &	51.4
\\ 
		AndCompareShape	&	93.2 		&	83.7	&	89.7	&&	&	80.0	&53.1	& &50.7\\ 

		
		
		
		
		
		
		
		\bottomrule
	\end{tabular}
}
	\label{results}
\end{table}


\begin{figure}
	\centering
	\caption{Comparison of SAMNet and COG on their abilities to generalize from the canonical to the hard dataset. We show three different settings: 1) (baseline) trained on canonical, tested on canonical 2) trained on canonical, tested on hard, 3) trained on canonical, fine tuned on hard, tested on hard. }
	
	\begin{tikzpicture}
	
	
	
	\tiny
	
	\begin{axis}[
	ybar,
	enlargelimits=0.15,
	legend style={at={(0.5,-0.15)},
		anchor=north,legend columns=-1},
	ylabel={COG test accuracy in \% },
	symbolic x coords={canonical/na/canonical, canonical/na/hard, canonical/hard/hard},
	xtick=data,
	nodes near coords,
	nodes near coords align={vertical},
	]
	\addplot coordinates {(canonical/na/canonical,98) (canonical/na/hard,91.6) (canonical/hard/hard,96.5)};
	\addplot coordinates {(canonical/na/canonical,96.7) (canonical/na/hard,65.9) (canonical/hard/hard,70)};
	\legend{SAMNet ,COG Model}
	\end{axis}
	\end{tikzpicture}
\end{figure}



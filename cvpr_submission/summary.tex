\section{Summary}

%In this paper we have introduced a novel Memory-Augmented Neural Network model called SAMNet. SAMNet was designed with the goal of learning to reason over video sequences and to answer questions about the content of the frames. When applied to the COG video reasoning dataset, the model outperformed the baseline model, showing significant improvements on the Hard variant of the dataset. The results indicate that the mechanisms introduced in SAMNet enable it to operate independent of the total number of frames or the number of distractions, and allow it to generalize to longer videos and more complex scenes. Observing attention maps shows that SAMNet can effectively perform multi-step reasoning over questions and frames as intended. Despite being trained only on image-question pairs with complex, compositional questions, SAMNet clearly learns to associate visual symbols with words and accurately classify temporal contexts as designed. Besides, the modelâ€™s reasoning using neural representations appears to be similar to how a human would operate on abstract symbols when solving the same task, including memorizing and recalling symbols (object embeddings) from the memory when needed. This is not perfect however and the system can sometimes store spurious objects despite the gating and reasoning mechanisms, but still give correct answers. This indicates at least two directions for possible further improvements. The first is to ameliorate content-based addressing with masking, similar to the improvements made for DNC proposed by [2]. Second is to implement variable number of reasoning steps, instead of hard-coded 8 steps, which could utilize Adaptive Computation Time (ACT) [5].

In this paper, through the introduction of a novel Memory-Augmented Neural Network model, SAMNet, we have quantified the impact of Transfer Learning in Visual Reasoning. Designed to learn to reason over sequences of frames (i.e., static images), SAMNet shows significant improvements, on the video reasoning dataset COG, over the corresponding baseline. Analysis of the results highlights the ability of the model to operate independently of the number of frames and generalize to samples with higher complexity, characterized by longer sequences or more complex scenes.
We also introduce a new taxonomy of transfer learning for visual reasoning, articulated around three axes: feature transfer, temporal transfer and reasoning transfer. To highlight the robustness of this taxonomy, we realize an extensive set of experiments with SAMNet over two datasets: COG and CLEVR, a diagnostic dataset for Question Answering over static images. SAMNet 
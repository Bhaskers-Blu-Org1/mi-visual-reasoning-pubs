\section{Transfer Learning}

\begin{figure*}
	\caption{Transfer learning taxonomy}
	\label{fig:taskonomy}
	\includegraphics[width=0.8\textwidth]{img/architecture/transfer_taxo}
\end{figure*}

We follow the notations in the survey by~\cite{pan-yang}.
A \emph{domain} is a pair $\cD = (\cX,P(X))$, where $\cX$ is a feature space and $P(X)$ is a marginal probability distribution.
For visual reasoning problems considered in this paper, 
$\cX$ will consist of purely visual inputs, i.e., either images or videos, in some cases, or 
a combination of both visual inputs and questions in other cases. 
A \emph{task} is a pair $\cT= (\cY,f(X))$, where $\cY$ is a label space and $f: \cX \to \cY$ is a prediction function. 
When the domain elements consist of both the question and the visual input, there is only one task, namely, to answer the 
question\footnote{%
	For the COG dataset, the answer is a tuple, one for each frame in the video, whereas for typical video answering datasets,
	only a single answer is needed for the entire video.}. % 
If the domain elements consist of just the visual inputs, then the task is defined by the question so that each question 
defines a separate task.
\begin{definition}[\cite{pan-yang}]
	Given a source domain $\cD_S$ and a source learning task $\cT_S$, a target domain $\cD_T$ and a target learning task $\cT_T$, transfer learning aims to help improve the 
	learning of the target predictive function $f_T(\cdot)$ in $\cD_T$ using the knowledge  in $\cD_S$ and $\cT_S$, where $\cD_S \ne \cD_T$, or $\cT_S \ne \cT_T$.
\end{definition}
In all our applications, $\cX_S = \cX_T$, so $\cD_S \ne \cD_T$ means that the marginal distributions $P_S$ and $P_T$ are different.
Similarly, $\cT_S \ne \cT_T$ means that either $Y_S \ne Y_T$ or that the associated prediction functions are different.

While the above definition is quite general, they do not adequately capture all the artifacts present in the visual reasoning.
For example, consider \emph{domain adaptation}, defined  in the transfer learning setting where the tasks $\cT_S$ and $\cT_T$ are the same 
but the marginal distributions $P_S$ and $P_T$ are different.
One setting is the case of static images, where this could be due to having different feature combinations in the source and
target but a different setting is in the context of video reasoning where the number of frames can be small in one case and 
large in another.
These require possibly very different methods, one involving building disentangled feature representations that can generalize across 
domains and another in which we might need memory-augmented neural networks that can generalize across frame lengths.
Another situation is when the  the questions themselves can be grouped in to families which entails studying transfer learning
in the context of different groups of questions, perhaps even all of them simultaneously.
This requires a slightly modifying the above definition.

Broadly, we consider 3 kinds of transfer learning problems in this work, as illustrated in~\cref{fig:taskonomy}. 
Let $\cQ$ denote the set of questions and $\cV$ denote the set of visual inputs.
\begin{description}
	\item[Feature Transfer:] In this setting of domain adaptation $\cX_S = \cX_T \subseteq \cQ \times \cV$
	and the task $f(q,v)$ is just the answer to the question $q$ on $v$.
	The marginal distributions $P_S$ and $P_T$ differ in the just the feature attributes such as shape, color, and size, or their combinations
	thereof.
	\item[Temporal Transfer:] This setting is similar to attribute adaptation in that $\cX_S = \cX_T \subseteq \cQ \times \cV$.
	The key difference is that we introduce a notion of complexity $C(v) = (n, m)$ for a visual input $v$,
	where $n$ equals the maximum number of objects $n$ in an image, and $m$
	equals  the number of frames in a vide. 
	For any visual input $v_S$ coming from $X_S$ with $C(v_S) = (n_S, m_S)$
	and for any visual input $v_T$ coming from $X_T$ with $C(v_T) = (n_T, m_T)$, we require that $n_T \ge n_S$ and 
	$m_T \ge m_S$ which at least one inequality being a strict one. 
	Thus, we necessarily increase the complexity of the visual input going from the source to the target domain.
	\item[Reasoning Transfer:]
\end{description}


